# Presentation Slides Outline
## Go Concurrency at Scale: Lessons from a Kubernetes Platform

---

## Slide 1: Title Slide
**Go Concurrency at Scale: Lessons from a Kubernetes Platform**

Real-World Patterns from Devtron

*Your Name*  
*Your Title*  
*Date*

---

## Slide 2: About Me (Optional)
- Your background
- Experience with Go
- Work on Devtron (Open-source Kubernetes platform)

---

## Slide 3: The Problem
**Why Basic Goroutines Aren't Enough**

```go
// This looks simple...
for _, item := range items {
    go processItem(item)
}
```

**But causes:**
- ðŸ”¥ Resource exhaustion (10,000 goroutines!)
- ðŸ”¥ No error handling
- ðŸ”¥ No coordination
- ðŸ”¥ No graceful shutdown

---

## Slide 4: What We'll Cover

1. **Worker Pools** - Bounded concurrency
2. **Fan-Out/Fan-In** - Parallel processing & aggregation
3. **Rate Limiting** - Protecting external services
4. **Graceful Shutdown** - Context & cancellation
5. **Real Case Study** - Processing thousands of API calls

All examples from **Devtron** - a production Kubernetes platform

---

## Slide 5: Pattern 1 - Worker Pools

**Problem:** Uncontrolled goroutine spawning

**Solution:** Process in batches

```go
batchSize := 5
for i := 0; i < totalItems; {
    var wg sync.WaitGroup
    for j := 0; j < batchSize; j++ {
        wg.Add(1)
        go func(index int) {
            defer wg.Done()
            processItem(items[index])
        }(i + j)
    }
    wg.Wait()
    i += batchSize
}
```

---

## Slide 6: Real Example - CI/CD Auto-Trigger

**Scenario:** After CI build succeeds, trigger 100+ CD pipelines

**File:** `pkg/workflow/dag/WorkflowDagExecutor.go`

**Without batching:**
- 100 goroutines spawned instantly
- Database connection pool exhausted
- System becomes unresponsive

**With batching (size=5):**
- Controlled resource usage
- Predictable performance
- Graceful degradation

---

## Slide 7: Worker Pool - Code Walkthrough

```go
// Real code from Devtron
totalCIArtifactCount := len(ciArtifactArr)
batchSize := impl.ciConfig.CIAutoTriggerBatchSize

for i := 0; i < totalCIArtifactCount; {
    remainingBatch := totalCIArtifactCount - i
    if remainingBatch < batchSize {
        batchSize = remainingBatch
    }
    
    var wg sync.WaitGroup
    for j := 0; j < batchSize; j++ {
        wg.Add(1)
        index := i + j
        go func(idx int) {
            defer wg.Done()
            err = impl.handleCiSuccessEvent(...)
        }(index)
    }
    wg.Wait()
    i += batchSize
}
```

---

## Slide 8: Pattern 2 - Fan-Out/Fan-In

**Pattern:** Distribute work, collect results

**Use Case:** Fetch CI and CD status in parallel

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Request   â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚           â”‚
   â”Œâ”€â”€â–¼â”€â”€â”    â”Œâ”€â”€â–¼â”€â”€â”
   â”‚ CI  â”‚    â”‚ CD  â”‚
   â”‚ API â”‚    â”‚ API â”‚
   â””â”€â”€â”¬â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”˜
      â”‚           â”‚
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
     â”‚   Response  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Slide 9: Fan-Out/Fan-In - Real Code

**File:** `api/restHandler/app/pipeline/configure/PipelineConfigRestHandler.go`

```go
wg := sync.WaitGroup{}
wg.Add(2)

// FAN-OUT
go func() {
    defer wg.Done()
    ciWorkflowStatus, err = handler.ciHandler.FetchCiStatusForTriggerView(appId)
}()

go func() {
    defer wg.Done()
    cdWorkflowStatus, err1 = handler.cdHandler.FetchAppWorkflowStatusForTriggerView(appId)
}()

// FAN-IN
wg.Wait()

// Combine results
triggerWorkflowStatus := pipelineConfig.TriggerWorkflowStatus{
    CiWorkflowStatus: ciWorkflowStatus,
    CdWorkflowStatus: cdWorkflowStatus,
}
```

**Performance:** 500ms â†’ 300ms (40% faster!)

---

## Slide 10: Advanced Fan-Out - Cluster Testing

**Scenario:** Test connection to 50+ Kubernetes clusters

**Challenge:** Collect results from all goroutines safely

**Solution:** `sync.Map` (thread-safe map)

```go
var wg sync.WaitGroup
respMap := &sync.Map{}

for _, cluster := range clusters {
    wg.Add(1)
    go func(c *ClusterBean) {
        defer wg.Done()
        err := testConnection(c)
        respMap.Store(c.Id, err)  // Thread-safe!
    }(cluster)
}

wg.Wait()
// Process all results from respMap
```

---

## Slide 11: Pattern 3 - Rate Limiting

**Problem:** Fetching 100+ Kubernetes resource manifests

**Without rate limiting:**
- 100+ concurrent Kubernetes API calls
- API server throttling
- Connection errors
- Unpredictable performance

**With batching:**
- 5 concurrent workers (configurable)
- Respects API rate limits
- Stable performance
- Predictable resource usage

---

## Slide 12: Rate Limiting - Real Code

**File:** `pkg/k8s/K8sCommonService.go`

```go
func GetManifestsByBatch(ctx context.Context, requests []ResourceRequest) []ResourceResponse {
    batchSize := 5  // Rate limit: max 5 concurrent K8s API calls
    totalRequests := len(requests)

    // Pre-allocate result slice
    results := make([]ResourceResponse, totalRequests)

    for i := 0; i < totalRequests; {
        remainingBatch := totalRequests - i
        if remainingBatch < batchSize {
            batchSize = remainingBatch
        }

        var wg sync.WaitGroup
        for j := 0; j < batchSize; j++ {
            wg.Add(1)
            index := i + j

            go func(idx int) {
                defer wg.Done()
                // Fetch from Kubernetes API
                response, err := GetResource(ctx, &requests[idx])
                // Thread-safe: each goroutine writes to its own index
                results[idx] = ResourceResponse{Manifest: response, Error: err}
            }(index)
        }

        wg.Wait()  // Wait for batch to complete
        i += batchSize
    }

    return results
}
```

---

## Slide 13: Rate Limiting - Performance

**Metrics from Production:**

| Scenario | Time | Concurrent API Calls |
|----------|------|---------------------|
| Sequential (100 resources) | 5 sec | 1 |
| Unlimited parallel | âŒ Throttled | 100+ |
| With batching (5 workers) | 1 sec | 5 |

**Result:** 5-10x faster + stable resource usage

---

## Slide 14: Pattern 4 - Graceful Shutdown

**Problem:** User closes browser, but server keeps processing

**Solution:** Context cancellation

```go
ctx, cancel := context.WithCancel(r.Context())

// Detect client disconnect
if cn, ok := w.(http.CloseNotifier); ok {
    go func(done <-chan struct{}, closed <-chan bool) {
        select {
        case <-done:
            // Request completed
        case <-closed:
            cancel()  // Client disconnected!
        }
    }(ctx.Done(), cn.CloseNotify())
}

// Pass context to service layer
result, err := service.Process(ctx, data)
```

---

## Slide 15: Context Cancellation - Benefits

**Saves Resources:**
- Cancel expensive Kubernetes API calls
- Stop database queries
- Prevent orphaned operations

**Real Impact:**
- User closes browser during cluster creation
- Context cancelled â†’ K8s API calls stopped
- Saved ~5 seconds of wasted API calls

---

## Slide 16: Advanced - SSE Broker Pattern

**File:** `api/sse/Broker.go`

Server-Sent Events for real-time updates

```go
func (br *Broker) run() {
    for {
        select {
        case <-br.shutdown:
            // Graceful shutdown
            for conn := range br.connections {
                br.shutdownConnection(conn)
            }
            return
            
        case conn := <-br.register:
            br.connections[conn] = true
            
        case msg := <-br.notifier:
            br.broadcastMessage(msg)
        }
    }
}
```

**Pattern:** `select` with multiple channels

---

## Slide 17: SSE - Non-Blocking Broadcast

```go
func (br *Broker) broadcastMessage(message SSEMessage) {
    for conn := range br.connections {
        select {
        case conn.outboundMessage <- message:
            // Sent successfully
        default:
            // Channel full - client too slow
            br.shutdownConnection(conn)
        }
    }
}
```

**Key:** `select` with `default` = non-blocking send

**Benefit:** Slow clients don't block fast clients

---

## Slide 18: Case Study - Hibernation Check

**Scenario:** Check if 100+ Kubernetes resources can be hibernated

**File:** `pkg/appStore/installedApp/service/FullMode/resource/ResourceTreeService.go`

**Challenges:**
1. 100+ API calls to Kubernetes
2. Need to count results (thread-safe)
3. Batch processing for rate limiting

**Patterns Used:**
- âœ… Worker pool
- âœ… Atomic counters
- âœ… Context propagation

---

## Slide 19: Hibernation Check - Code

```go
var canBeHibernated uint64 = 0
var hibernated uint64 = 0

batchSize := 10
for i := 0; i < len(replicaNodes); {
    var wg sync.WaitGroup
    for j := 0; j < batchSize; j++ {
        wg.Add(1)
        go func(j int) {
            defer wg.Done()
            
            canHibernate, isHibernated := checkNode(replicaNodes[i+j])
            
            // Atomic operations - thread-safe!
            if canHibernate {
                atomic.AddUint64(&canBeHibernated, 1)
            }
            if isHibernated {
                atomic.AddUint64(&hibernated, 1)
            }
        }(j)
    }
    wg.Wait()
    i += batchSize
}
```

---

## Slide 20: Hibernation Check - Performance

**Sequential Processing:**
- 100 resources Ã— 50ms = 5 seconds

**Parallel (no batching):**
- Kubernetes API rate limiting kicks in
- Requests fail

**Batched (10 workers):**
- ~500ms total
- **10x faster!**
- No rate limiting issues

---

## Slide 21: Best Practices - DO âœ…

1. **Always use worker pools** for bounded concurrency
2. **Use `sync.WaitGroup`** for coordinating goroutines
3. **Use `context.Context`** for cancellation
4. **Use `sync.Map`** or mutexes for shared state
5. **Use `atomic`** for simple counters
6. **Use `select` with `default`** for non-blocking ops
7. **Always `defer wg.Done()`** to prevent deadlocks

---

## Slide 22: Best Practices - DON'T âŒ

1. âŒ Spawn unlimited goroutines
2. âŒ Share memory without synchronization
3. âŒ Ignore context cancellation
4. âŒ Forget error handling in goroutines
5. âŒ Use channels when `sync.WaitGroup` is simpler
6. âŒ Forget to close channels (can cause goroutine leaks)

---

## Slide 23: Common Pitfalls

**Pitfall 1: Goroutine Leaks**
```go
// BAD: Goroutine never exits
go func() {
    for {
        doWork()  // No exit condition!
    }
}()
```

**Pitfall 2: Forgetting wg.Done()**
```go
// BAD: Deadlock!
wg.Add(1)
go func() {
    doWork()
    // Forgot wg.Done()!
}()
wg.Wait()  // Waits forever
```

---

## Slide 24: Performance Summary

**Real metrics from Devtron:**

| Operation | Before | After | Improvement |
|-----------|--------|-------|-------------|
| CI Auto-trigger (100 pipelines) | âŒ Crash | 2s | âˆž |
| Workflow status fetch | 500ms | 300ms | 40% |
| K8s resource fetch (100 items) | 5s | 1s | 5x |
| Hibernation check (100 resources) | 5s | 500ms | 10x |
| Cluster connection test (50 clusters) | 25s | 3s | 8.3x |

---

## Slide 25: When to Use Each Pattern

**Worker Pool:**
- Processing large datasets
- Batch operations
- Rate limiting external APIs

**Fan-Out/Fan-In:**
- Parallel independent operations
- Aggregating results from multiple sources

**Context Cancellation:**
- HTTP request handlers
- Long-running operations
- Graceful shutdown

**Atomic Operations:**
- Simple counters
- Flags/booleans
- When mutex is overkill

---

## Slide 26: Tools & Libraries

**Standard Library:**
- `sync.WaitGroup` - Coordination
- `sync.Map` - Thread-safe map
- `sync/atomic` - Atomic operations
- `context` - Cancellation

**Extended Library:**
- `golang.org/x/sync/errgroup` - Error handling
- `golang.org/x/time/rate` - Rate limiting
- `golang.org/x/sync/semaphore` - Weighted semaphores

---

## Slide 27: Resources

**Code Examples:**
- Devtron GitHub: https://github.com/devtron-labs/devtron
- Files from this talk available in repo

**Further Reading:**
- Go Concurrency Patterns (Rob Pike)
- Effective Go: Concurrency
- Go Blog: Pipelines and Cancellation

**Practice:**
- Clone Devtron and explore the patterns
- Try the examples in `go-concurrency-examples.go`

---

## Slide 28: Key Takeaways

1. **Goroutines are cheap, but not free** - Use worker pools
2. **Coordination is key** - WaitGroup, channels, context
3. **Think about failure** - Error handling, timeouts, cancellation
4. **Measure performance** - Before and after optimization
5. **Start simple** - Add complexity only when needed

**Remember:** Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.

---

## Slide 29: Thank You!

**Questions?**

**Connect:**
- GitHub: @devtron-labs
- Website: devtron.ai
- Twitter: @DevtronL

**Try Devtron:**
- Open-source Kubernetes platform
- See these patterns in action
- Contributions welcome!

---

## Slide 30: Bonus - Live Demo

**Let's run the examples!**

```bash
go run go-concurrency-examples.go
```

**What we'll see:**
1. Worker pool in action
2. Fan-out/fan-in timing
3. Atomic counters
4. Context cancellation
5. Graceful shutdown

---

## Speaker Notes

### Timing (25 minutes):
- Slides 1-4: Introduction (2 min)
- Slides 5-7: Worker Pools (6 min)
- Slides 8-10: Fan-Out/Fan-In (5 min)
- Slides 11-13: Rate Limiting (4 min)
- Slides 14-17: Graceful Shutdown (4 min)
- Slides 18-20: Case Study (3 min)
- Slides 21-28: Best Practices & Wrap-up (1 min)

### Tips:
- Show code in IDE for better syntax highlighting
- Run live demos if time permits
- Have backup slides ready for Q&A
- Prepare answers for common questions about Devtron

